import createContextHook from '@/utils/createContextHook';
import { useState, useRef, useEffect, useCallback, useMemo } from 'react';
import * as FileSystem from 'expo-file-system/legacy';
import * as MediaLibrary from 'expo-media-library';
import { Platform, Alert, ToastAndroid } from 'react-native';
import { CameraView, useCameraPermissions } from 'expo-camera';
import FirebaseService from '@/services/FirebaseService';
import { firebaseConfig } from '@/config/firebase';
import type { P2PMessage } from '@/services/FirebaseService';
import VideoMerger from '@/modules/VideoMerger';
import RecordingConfig from '@/constants/recording';

interface VideoSegment {
    uri: string;
    timestamp: number;
    duration: number;
    recordedAt: number;
}

interface Highlight {
    id: string;
    timestamp: Date;
    duration: number;
    uri: string;
}

interface ProcessingState {
    isProcessing: boolean;
    highlightId: string | null;
    progress: string;
}

export const [RecordingProvider, useRecording] = createContextHook(() => {
    const [isRecording, setIsRecording] = useState<boolean>(false);
    const [highlights, setHighlights] = useState<Highlight[]>([]);
    const [isConnected, setIsConnected] = useState<boolean>(false);
    const [deviceRole, setDeviceRole] = useState<'camera' | 'remote' | null>(null);
    const [serverAddress, setServerAddress] = useState<string>('');
    const [processingState, setProcessingState] = useState<ProcessingState>({
        isProcessing: false,
        highlightId: null,
        progress: '',
    });
    const [mediaPermission, requestMediaPermission] = MediaLibrary.usePermissions();
    const [cameraPermission, requestCameraPermission] = useCameraPermissions();

    const videoSegments = useRef<VideoSegment[]>([]);
    const cameraRef = useRef<CameraView | null>(null);
    const isRecordingRef = useRef<boolean>(false);
    const messageUnsubscribe = useRef<(() => void) | null>(null);
    const connectionUnsubscribe = useRef<(() => void) | null>(null);
    const recordingStartTime = useRef<number>(0);

    const showToast = useCallback((message: string) => {
        if (Platform.OS === 'android') {
            ToastAndroid.show(message, ToastAndroid.LONG);
        }
        console.log('üì± Toast:', message);
    }, []);

    useEffect(() => {
        try {
            FirebaseService.initialize(firebaseConfig);
            console.log('‚úÖ Firebase initialized');
        } catch (error) {
            console.error('‚ùå Firebase initialization error:', error);
        }

        loadHighlights();

        return () => {
            disconnect();
        };
    }, []);

    const loadHighlights = useCallback(async () => {
        try {
            const highlightDir = `${FileSystem.documentDirectory}${RecordingConfig.HIGHLIGHTS_FOLDER}`;
            const dirInfo = await FileSystem.getInfoAsync(highlightDir);

            if (dirInfo.exists) {
                const files = await FileSystem.readDirectoryAsync(highlightDir);
                const loadedHighlights = files
                    .filter(f => f.endsWith('.mp4'))
                    .map(filename => {
                        const id = filename.replace('.mp4', '');
                        const timestamp = parseInt(id.split('_')[1]) || Date.now();

                        return {
                            id,
                            timestamp: new Date(timestamp),
                            duration: RecordingConfig.BUFFER_DURATION,
                            uri: `${highlightDir}${filename}`,
                        };
                    });

                setHighlights(loadedHighlights.sort((a, b) =>
                    b.timestamp.getTime() - a.timestamp.getTime()
                ));
            }
        } catch (error) {
            console.error('Failed to load highlights:', error);
        }
    }, []);

    /**
     * üéØ CAPTURE HIGHLIGHT - POPRAWIONA LOGIKA
     *
     * KLUCZOWE ZMIANY:
     * 1. Zatrzymuje aktualny segment przed wycinaniem (aby mieƒá pe≈Çne requestedDuration)
     * 2. Prawid≈Çowo oblicza kt√≥re segmenty potrzebujemy
     * 3. Automatycznie wznawia nagrywanie po wycinaniu
     */
    const captureHighlight = useCallback(async (requestedDuration: number = 120) => {
        console.log('üé¨ Capture highlight requested:', requestedDuration, 'seconds');

        if (!isRecordingRef.current) {
            Alert.alert('B≈ÇƒÖd', 'Nagrywanie nie jest aktywne');
            return;
        }

        if (processingState.isProcessing) {
            showToast('‚è≥ Proszƒô czekaƒá, przetwarzam poprzednie nagranie...');
            return;
        }

        // üî• KRYTYCZNE: Zatrzymaj aktualny segment aby go sfinalizowaƒá
        console.log('‚è∏Ô∏è Pausing recording to finalize current segment...');
        const wasRecording = isRecordingRef.current;

        try {
            if (cameraRef.current) {
                await cameraRef.current.stopRecording();
            }
        } catch (error) {
            console.warn('‚ö†Ô∏è Stop recording warning:', error);
        }

        // Poczekaj chwilƒô a≈º segment zostanie dodany do bufora
        await new Promise(resolve => setTimeout(resolve, 500));

        const now = Date.now();
        const requestedStartTime = now - (requestedDuration * 1000);

        console.log('‚è±Ô∏è Time range:');
        console.log(`   Now: ${new Date(now).toISOString()}`);
        console.log(`   Requested start: ${new Date(requestedStartTime).toISOString()}`);
        console.log(`   Duration: ${requestedDuration}s`);

        // Znajd≈∫ wszystkie segmenty kt√≥re pokrywajƒÖ siƒô z naszym zakresem czasowym
        const relevantSegments = videoSegments.current
            .filter(seg => {
                const segmentEnd = seg.recordedAt + seg.duration;
                // Segment overlaps if: segment_end > requested_start AND segment_start < now
                return segmentEnd > requestedStartTime && seg.recordedAt < now;
            })
            .sort((a, b) => a.recordedAt - b.recordedAt);

        if (relevantSegments.length === 0) {
            Alert.alert('B≈ÇƒÖd', 'Brak nagra≈Ñ z tego okresu. Poczekaj chwilƒô i spr√≥buj ponownie.');
            return;
        }

        console.log(`üìä Found ${relevantSegments.length} relevant segments:`);
        relevantSegments.forEach((seg, i) => {
            const start = new Date(seg.recordedAt).toISOString();
            const end = new Date(seg.recordedAt + seg.duration).toISOString();
            console.log(`  ${i + 1}. ${start} ‚Üí ${end} (${(seg.duration / 1000).toFixed(1)}s)`);
        });

        const highlightId = `highlight_${Date.now()}`;

        try {
            setProcessingState({
                isProcessing: true,
                highlightId,
                progress: 'Przygotowywanie...',
            });

            showToast(`üé¨ Przetwarzam ${requestedDuration}s nagrania...`);

            if (!mediaPermission?.granted) {
                const { granted } = await requestMediaPermission();
                if (!granted) {
                    Alert.alert('B≈ÇƒÖd', 'Brak uprawnie≈Ñ do zapisywania w galerii');
                    setProcessingState({ isProcessing: false, highlightId: null, progress: '' });
                    return;
                }
            }

            const highlightDir = `${FileSystem.documentDirectory}${RecordingConfig.HIGHLIGHTS_FOLDER}`;
            await FileSystem.makeDirectoryAsync(highlightDir, { intermediates: true });

            const outputUri = `${highlightDir}${highlightId}.mp4`;

            // üî• POPRAWIONA LOGIKA: U≈ºyj NOWEJ funkcji mergePreciseClip
            // kt√≥ra u≈ºywa re-encoding dla idealnego po≈ÇƒÖczenia bez szarpa≈Ñ

            setProcessingState({
                isProcessing: true,
                highlightId,
                progress: `≈ÅƒÖczƒô ${relevantSegments.length} segment√≥w...`,
            });

            console.log('üîÑ Starting merge with re-encoding for seamless result...');

            try {
                // U≈ºyj NOWEJ funkcji mergePreciseClip zamiast extractPreciseClip
                const mergedPath = await VideoMerger.mergePreciseClip(
                    relevantSegments.map(seg => seg.uri),
                    requestedStartTime,    // Globalny timestamp poczƒÖtku
                    requestedDuration,      // Dok≈Çadna d≈Çugo≈õƒá w sekundach
                    relevantSegments.map(seg => seg.recordedAt), // Timestampy poczƒÖtku ka≈ºdego segmentu
                    outputUri
                );

                console.log('‚úÖ Merge completed!', mergedPath);

                setProcessingState({
                    isProcessing: true,
                    highlightId,
                    progress: 'Zapisywanie do galerii...',
                });

                const fileInfo = await FileSystem.getInfoAsync(mergedPath);
                if (!fileInfo.exists) {
                    throw new Error('Merged file not created');
                }

                console.log(`üì¶ Output file size: ${(fileInfo.size / 1024 / 1024).toFixed(2)}MB`);

                // Zapisz do galerii
                const asset = await MediaLibrary.createAssetAsync(mergedPath);
                const albums = await MediaLibrary.getAlbumsAsync();
                const existingAlbum = albums.find(album => album.title === RecordingConfig.GALLERY_ALBUM_NAME);

                if (existingAlbum) {
                    await MediaLibrary.addAssetsToAlbumAsync([asset], existingAlbum, false);
                } else {
                    await MediaLibrary.createAlbumAsync(RecordingConfig.GALLERY_ALBUM_NAME, asset, false);
                }

                const newHighlight: Highlight = {
                    id: highlightId,
                    timestamp: new Date(),
                    duration: requestedDuration,
                    uri: mergedPath,
                };

                setHighlights((prev) => [newHighlight, ...prev]);

                setProcessingState({
                    isProcessing: false,
                    highlightId: null,
                    progress: '',
                });

                showToast(`‚úÖ Akcja ${requestedDuration}s zapisana w galerii!`);

                Alert.alert(
                    '‚úÖ Gotowe!',
                    `Nagranie ${requestedDuration}s zapisane bez szarpa≈Ñ\n` +
                    `(${relevantSegments.length} segment√≥w po≈ÇƒÖczonych)`,
                    [{ text: 'OK' }]
                );

                console.log('üéâ Highlight captured successfully!');

                // üî• KRYTYCZNE: Wzn√≥w nagrywanie je≈õli by≈Ço aktywne
                if (wasRecording) {
                    console.log('‚ñ∂Ô∏è Resuming recording...');
                    await new Promise(resolve => setTimeout(resolve, 200));

                    // Restart recording loop
                    const recordSegment = async (): Promise<void> => {
                        if (!isRecordingRef.current || !cameraRef.current) {
                            return;
                        }

                        try {
                            const segmentStartTime = Date.now();
                            const video = await cameraRef.current.recordAsync({
                                maxDuration: RecordingConfig.SEGMENT_DURATION,
                            });

                            if (video && video.uri && isRecordingRef.current) {
                                const segmentEndTime = Date.now();
                                const actualDuration = segmentEndTime - segmentStartTime;

                                const segment: VideoSegment = {
                                    uri: video.uri,
                                    timestamp: segmentEndTime,
                                    recordedAt: segmentStartTime,
                                    duration: actualDuration,
                                };

                                videoSegments.current.push(segment);

                                // Usu≈Ñ stare segmenty
                                const cutoffTime = Date.now() - (RecordingConfig.BUFFER_DURATION + 10) * 1000;
                                videoSegments.current = videoSegments.current.filter(
                                    seg => seg.recordedAt > cutoffTime
                                );

                                console.log(`üì¶ Buffer: ${videoSegments.current.length} segments`);

                                await new Promise(resolve => setTimeout(resolve, 100));
                                await recordSegment();
                            }
                        } catch (error) {
                            console.error('Recording error after resume:', error);
                        }
                    };

                    recordSegment();
                }

            } catch (mergeError) {
                console.error('‚ùå Video merge failed:', mergeError);
                setProcessingState({
                    isProcessing: false,
                    highlightId: null,
                    progress: '',
                });

                Alert.alert(
                    'B≈ÇƒÖd ≈ÇƒÖczenia wideo',
                    'Nie uda≈Ço siƒô po≈ÇƒÖczyƒá segment√≥w. Sprawd≈∫ logi.'
                );

                // üî• Wzn√≥w nagrywanie nawet w przypadku b≈Çƒôdu
                if (wasRecording && isRecordingRef.current) {
                    console.log('‚ñ∂Ô∏è Resuming recording after error...');
                    // U≈ºyj tej samej logiki co wy≈ºej
                    const recordSegment = async (): Promise<void> => {
                        if (!isRecordingRef.current || !cameraRef.current) return;
                        try {
                            const segmentStartTime = Date.now();
                            const video = await cameraRef.current.recordAsync({
                                maxDuration: RecordingConfig.SEGMENT_DURATION,
                            });
                            if (video && video.uri && isRecordingRef.current) {
                                const segmentEndTime = Date.now();
                                const segment: VideoSegment = {
                                    uri: video.uri,
                                    timestamp: segmentEndTime,
                                    recordedAt: segmentStartTime,
                                    duration: segmentEndTime - segmentStartTime,
                                };
                                videoSegments.current.push(segment);
                                const cutoffTime = Date.now() - (RecordingConfig.BUFFER_DURATION + 10) * 1000;
                                videoSegments.current = videoSegments.current.filter(seg => seg.recordedAt > cutoffTime);
                                await new Promise(resolve => setTimeout(resolve, 100));
                                await recordSegment();
                            }
                        } catch (error) {
                            console.error('Recording error after resume:', error);
                        }
                    };
                    recordSegment();
                }
            }

        } catch (error) {
            console.error('Failed to capture highlight:', error);
            setProcessingState({
                isProcessing: false,
                highlightId: null,
                progress: '',
            });
            Alert.alert('B≈ÇƒÖd', `Nie uda≈Ço siƒô zapisaƒá akcji: ${error}`);

            // üî• Wzn√≥w nagrywanie nawet w przypadku b≈Çƒôdu
            if (wasRecording && isRecordingRef.current) {
                console.log('‚ñ∂Ô∏è Resuming recording after error...');
                const recordSegment = async (): Promise<void> => {
                    if (!isRecordingRef.current || !cameraRef.current) return;
                    try {
                        const segmentStartTime = Date.now();
                        const video = await cameraRef.current.recordAsync({
                            maxDuration: RecordingConfig.SEGMENT_DURATION,
                        });
                        if (video && video.uri && isRecordingRef.current) {
                            const segmentEndTime = Date.now();
                            const segment: VideoSegment = {
                                uri: video.uri,
                                timestamp: segmentEndTime,
                                recordedAt: segmentStartTime,
                                duration: segmentEndTime - segmentStartTime,
                            };
                            videoSegments.current.push(segment);
                            const cutoffTime = Date.now() - (RecordingConfig.BUFFER_DURATION + 10) * 1000;
                            videoSegments.current = videoSegments.current.filter(seg => seg.recordedAt > cutoffTime);
                            await new Promise(resolve => setTimeout(resolve, 100));
                            await recordSegment();
                        }
                    } catch (error) {
                        console.error('Recording error after resume:', error);
                    }
                };
                recordSegment();
            }
        }
    }, [mediaPermission, requestMediaPermission, processingState, showToast]);

    const startAsCamera = useCallback(async () => {
        try {
            if (!cameraPermission?.granted) {
                const { granted } = await requestCameraPermission();
                if (!granted) {
                    Alert.alert('B≈ÇƒÖd', 'Brak uprawnie≈Ñ do kamery');
                    return;
                }
            }

            FirebaseService.setDeviceRole('camera');
            const sessionId = await FirebaseService.startAsCamera();
            setServerAddress(sessionId);
            setDeviceRole('camera');

            messageUnsubscribe.current = FirebaseService.onMessage((message: P2PMessage) => {
                console.log('üìπ Camera received:', message.type);

                if (message.type === 'capture') {
                    const duration = (message.duration || 120);
                    console.log(`üé¨ Capture signal! Duration: ${duration}s`);
                    captureHighlight(duration);
                } else if (message.type === 'register') {
                    console.log('‚úÖ Remote registered');
                }
            });

            connectionUnsubscribe.current = FirebaseService.onConnection((connected) => {
                setIsConnected(connected);
                if (connected) {
                    console.log('‚úÖ Pilot connected');
                    Alert.alert('Po≈ÇƒÖczono', 'Pilot zosta≈Ç po≈ÇƒÖczony!');
                } else {
                    console.log('‚ùå Pilot disconnected');
                }
            });

            console.log('‚úÖ Camera mode ready');
            console.log(`üîë Session ID: ${sessionId}`);

        } catch (error) {
            console.error('Failed to start camera:', error);
            Alert.alert('B≈ÇƒÖd', 'Nie uda≈Ço siƒô uruchomiƒá trybu kamery.');
        }
    }, [cameraPermission, requestCameraPermission, captureHighlight]);

    const connectToCamera = useCallback(async (sessionId: string) => {
        try {
            FirebaseService.setDeviceRole('remote');
            const connected = await FirebaseService.connectToCamera(sessionId);

            if (connected) {
                setIsConnected(true);
                setServerAddress('Connected');
                setDeviceRole('remote');

                messageUnsubscribe.current = FirebaseService.onMessage((message: P2PMessage) => {
                    console.log('üéÆ Remote received:', message.type);
                });

                console.log('‚úÖ Connected to camera');
                Alert.alert('Sukces', 'Po≈ÇƒÖczono z kamerƒÖ!');
            }
        } catch (error) {
            console.error('Failed to connect:', error);
            setIsConnected(false);
            Alert.alert('B≈ÇƒÖd po≈ÇƒÖczenia', 'Nie uda≈Ço siƒô po≈ÇƒÖczyƒá z kamerƒÖ.');
        }
    }, []);

    const sendCaptureSignal = useCallback((duration: number = 120) => {
        if (!isConnected) {
            Alert.alert('B≈ÇƒÖd', 'Brak po≈ÇƒÖczenia z kamerƒÖ');
            return;
        }

        FirebaseService.sendMessage({
            type: 'capture',
            timestamp: Date.now(),
            duration: duration
        });

        console.log(`üì§ Capture signal sent (${duration}s)`);
    }, [isConnected]);

    const disconnect = useCallback(() => {
        if (messageUnsubscribe.current) {
            messageUnsubscribe.current();
            messageUnsubscribe.current = null;
        }

        if (connectionUnsubscribe.current) {
            connectionUnsubscribe.current();
            connectionUnsubscribe.current = null;
        }

        FirebaseService.disconnect();
        setIsConnected(false);
        setDeviceRole(null);
        setServerAddress('');

        if (isRecordingRef.current) {
            stopRecording();
        }
    }, []);

    const startRecording = useCallback(async () => {
        if (!cameraRef.current) {
            Alert.alert('B≈ÇƒÖd', 'Kamera nie jest gotowa');
            return;
        }

        try {
            setIsRecording(true);
            isRecordingRef.current = true;
            videoSegments.current = [];
            recordingStartTime.current = Date.now();

            console.log('üé• Starting continuous recording...');
            console.log(`üìä Segment duration: ${RecordingConfig.SEGMENT_DURATION}s`);

            await new Promise(resolve => setTimeout(resolve, 500));

            const recordSegment = async (): Promise<void> => {
                if (!isRecordingRef.current || !cameraRef.current) {
                    console.log('‚èπÔ∏è Recording stopped');
                    return;
                }

                const segmentStartTime = Date.now();
                let retryCount = 0;
                const maxRetries = 3;

                while (retryCount < maxRetries && isRecordingRef.current) {
                    try {
                        console.log(`üìπ Recording ${RecordingConfig.SEGMENT_DURATION}s segment...`);

                        const video = await cameraRef.current.recordAsync({
                            maxDuration: RecordingConfig.SEGMENT_DURATION,
                        });

                        if (video && video.uri) {
                            const segmentEndTime = Date.now();
                            const actualDuration = segmentEndTime - segmentStartTime;

                            console.log(`‚úÖ Segment recorded: ${(actualDuration / 1000).toFixed(1)}s`);

                            const segment: VideoSegment = {
                                uri: video.uri,
                                timestamp: segmentEndTime,
                                recordedAt: segmentStartTime,
                                duration: actualDuration,
                            };

                            videoSegments.current.push(segment);

                            // Usu≈Ñ stare segmenty poza buforem
                            const cutoffTime = Date.now() - (RecordingConfig.BUFFER_DURATION + 10) * 1000;
                            const oldSegments = videoSegments.current.filter(
                                seg => seg.recordedAt <= cutoffTime
                            );

                            for (const oldSeg of oldSegments) {
                                try {
                                    await FileSystem.deleteAsync(oldSeg.uri, { idempotent: true });
                                    console.log('üóëÔ∏è Deleted old segment');
                                } catch (e) {
                                    console.warn('Delete error:', e);
                                }
                            }

                            videoSegments.current = videoSegments.current.filter(
                                seg => seg.recordedAt > cutoffTime
                            );

                            const bufferSeconds = (Date.now() - recordingStartTime.current) / 1000;
                            console.log(`üì¶ Buffer: ${videoSegments.current.length} segments (${bufferSeconds.toFixed(1)}s recorded)`);

                            await new Promise(resolve => setTimeout(resolve, 100));

                            break;
                        }
                    } catch (error) {
                        retryCount++;
                        console.error(`‚ùå Segment error (${retryCount}/${maxRetries}):`, error);

                        if (retryCount >= maxRetries) {
                            Alert.alert(
                                'B≈ÇƒÖd nagrywania',
                                'Nie uda≈Ço siƒô nagraƒá segmentu.',
                                [{ text: 'OK', onPress: () => {
                                        setIsRecording(false);
                                        isRecordingRef.current = false;
                                    }}]
                            );
                            return;
                        }

                        await new Promise(resolve => setTimeout(resolve, 1000 * Math.pow(2, retryCount - 1)));
                    }
                }

                if (isRecordingRef.current) {
                    await recordSegment();
                }
            };

            await recordSegment();

        } catch (error) {
            console.error('Failed to start recording:', error);
            Alert.alert('B≈ÇƒÖd', 'Nie uda≈Ço siƒô rozpoczƒÖƒá nagrywania');
            setIsRecording(false);
            isRecordingRef.current = false;
        }
    }, []);

    const stopRecording = useCallback(async () => {
        console.log('üõë Stopping recording...');
        setIsRecording(false);
        isRecordingRef.current = false;

        if (cameraRef.current) {
            try {
                await cameraRef.current.stopRecording();
            } catch (error) {
                console.warn('Stop error:', error);
            }
        }

        console.log(`üíæ Keeping ${videoSegments.current.length} segments for potential capture`);

        setTimeout(async () => {
            if (!isRecordingRef.current) {
                for (const segment of videoSegments.current) {
                    try {
                        await FileSystem.deleteAsync(segment.uri, { idempotent: true });
                    } catch (error) {
                        console.warn('Delete error:', error);
                    }
                }
                videoSegments.current = [];
                console.log('üóëÔ∏è Cleared all segments');
            }
        }, 30000);

        console.log('‚úÖ Recording stopped');
    }, []);

    const deleteHighlight = useCallback(async (id: string) => {
        try {
            const highlight = highlights.find(h => h.id === id);
            if (highlight) {
                await FileSystem.deleteAsync(highlight.uri, { idempotent: true });

                try {
                    const assets = await MediaLibrary.getAssetsAsync({
                        first: 1000,
                        album: RecordingConfig.GALLERY_ALBUM_NAME,
                    });

                    const asset = assets.assets.find(a => a.uri === highlight.uri);
                    if (asset) {
                        await MediaLibrary.deleteAssetsAsync([asset]);
                    }
                } catch (error) {
                    console.warn('Gallery delete error:', error);
                }

                setHighlights(prev => prev.filter(h => h.id !== id));
                console.log('‚úÖ Highlight deleted:', id);
            }
        } catch (error) {
            console.error('Failed to delete highlight:', error);
        }
    }, [highlights]);

    const setCameraReference = useCallback((ref: CameraView | null) => {
        cameraRef.current = ref;
    }, []);

    return useMemo(() => ({
        isRecording,
        highlights,
        isConnected,
        deviceRole,
        serverAddress,
        processingState,
        startRecording,
        stopRecording,
        captureHighlight,
        deleteHighlight,
        startAsCamera,
        connectToCamera,
        sendCaptureSignal,
        disconnect,
        setCameraReference,
    }), [
        isRecording,
        highlights,
        isConnected,
        deviceRole,
        serverAddress,
        processingState,
        startRecording,
        stopRecording,
        captureHighlight,
        deleteHighlight,
        startAsCamera,
        connectToCamera,
        sendCaptureSignal,
        disconnect,
        setCameraReference,
    ]);
});